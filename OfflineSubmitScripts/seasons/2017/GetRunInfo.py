#!/usr/bin/env python

"""
Gather information about recent runs from live database and migrate it to
the prodcution databases (i3filter on filter-db).
"""

from libs.config import get_config
from libs.argparser import get_defaultparser
from libs.logger import get_logger
from libs.path import get_logdir
from libs.runs import Run, validate_file_integrity
from libs.databaseconnection import DatabaseConnection
from libs import times
from libs.process import Lock
from libs.cron import cron_finished, send_custom_message
from libs.utils import Counter

import os

def send_check_notification(new_records, changed_records, logger, dryrun):
    from libs.email import send_email

    receivers = get_config(logger).get_var_list('GetRunInfo', 'NotificationReceiver')

    message = """
        *** This is an automated message generated by the *** <br>
        ***        GetRunInfo system of L2 Processing     *** <br><br>
        
        A new snapshot is available!

        New Runs: {new_runs}
        Changed Runs: {changed_runs}
        """.format(new_runs = new_records, changed_runs = changed_records)

    send_email(receivers, 'A new snapshot is available!', message, logger, dryrun)

def updated_runs_manual_check(runs, logger):
    ok = False

    actions = []

    logger.info('Please define actions for runs with an updated snapshot.')
    logger.info('Actions:')
    logger.info('   I: Ignore')
    logger.info('   U: Update')
    logger.info('   Q: Exit script')
    while not ok:
        actions = []
        for run_id, snapshot_id in runs.items():
            ok_action = False

            while not ok_action:
                action = raw_input('Run {0}, new snapshot id {1}: '.format(run_id, snapshot_id))

                action = action.upper()
                if action == 'I' or action == 'U' or action == 'Q':
                    logger.info('Run {0}, new snapshot id {1}: {2}'.format(run_id, snapshot_id, action))
                    ok_action = True
                else:
                    logger.error('Invalid action')

            if action == 'Q':
                logger.info('Stop script.')
                exit()

            actions.append({'run_id': run_id, 'snapshot_id': snapshot_id, 'action': action})

        logger.info('*******************')
        logger.info('Summary of actions:')
        for action in actions:
            logger.info('  Run {run_id}, snapshot id {snapshot_id}: {action}'.format(**action))

        ok_approved = False
        while not ok_approved:
            approved = raw_input('Is this correct? (Y/N): ')

            if approved.upper() in ('Y', 'N'):
                logger.info('Is this correct? (Y/N): {}'.format(approved.upper()))
                ok_approved = True

                if approved.upper() == 'Y':
                    ok = True
            else:
                logger.error('Invalid option. Try again.')

    return actions

def mark_ignored_run_snapshots(actions, db, logger, dryrun):
    sql = 'INSERT INTO i3filter.runs_ignored (run_id, snapshot_id, `comment`, `date`) VALUES (%(run_id)s, %(snapshot_id)s, %(comment)s, NOW())'

    for action in actions:
        if action['action'] == 'I':
            logger.debug('Ignore: {}'.format(action))

            if not dryrun:
                db.execute(sql, {'run_id': action['run_id'], 'snapshot_id': action['snapshot_id'], 'comment': 'Manually ignored'})

def get_ignored_run_snapshots(db, logger):
    sql = 'SELECT run_id, snapshot_id FROM i3filter.runs_ignored'
    return db.fetchall(sql)

def main(inputfiletype, logger, dryrun, check, skip_file_validation, cron):
    counter = Counter(['handled', 'imported', 'error', 'updated'])

    if check:
        logger.info('Only in check mode. Just checking if an update is available.')

    db_filter = DatabaseConnection.get_connection('filter-db', logger)
    db_i3live = DatabaseConnection.get_connection('i3live', logger)

    config = get_config(logger)

    # Get the current production version and snapshot info
    # from the production database
    current_info = db_filter.fetchall("""
        SELECT
            MAX(snapshot_id) as max_snapshot_id,
            MAX(production_version) as max_production_version
        FROM i3filter.runs
    """)[0]

    current_info['snapshot_id'] = current_info['max_snapshot_id'] or 0
    current_info['production_version'] = current_info['max_production_version'] or 0

    logger.debug("Got current max production_version {max_production_version} and max snapshot_id {max_snapshot_id} from i3filter.runs".format(**current_info))

    seasons = config.get_seasons_info()
    current_season = config.getint('DEFAULT', 'Season')

    # First run of current season
    first_run = seasons[current_season]['first']  # 

    # If it is -1 (that means the season hasn't begun yet) replace it with a very high number
    # to enable processing the test runs
    if first_run == -1:
        first_run = 9999999

    # Dfeault last run. If no next season is defined, this value will be kept
    last_run = 9999999

    # If a next season is defined, we need to exclude those test runs
    exclude_next_testruns = [-1]
 
    if current_season + 1 in seasons:
        if seasons[current_season + 1]['first'] > -1:
            # last run of the current season is the start run of the next season minus one
            last_run = seasons[current_season + 1]['first'] - 1

        # The test run can be known but not the first run
        exclude_next_testruns = seasons[current_season + 1]['test']

    # get the newest data from the live db      
    livesql = """
        SELECT
            r.runNumber, r.tStart, r.tStop,
            r.tStart_frac, r.tStop_frac, r.nEvents, r.rateHz,
            l.snapshot_id, l.good_i3, l.good_it, l.reason_i3, l.reason_it,
            l.good_tstart, l.good_tstart_frac, l.good_tstop,l.good_tstop_frac
        FROM live.livedata_snapshotrun l
        JOIN live.livedata_run r
            ON l.run_id = r.id
        WHERE (r.runNumber >= {first_run} OR r.runNumber IN ({test_runs}))
            AND r.runNumber <= {last_run}
            AND r.runNumber NOT IN ({exclude_next_testruns})
        ORDER BY l.snapshot_id
    """.format(
            first_run = first_run,
            test_runs = ','.join([str(r) for r in seasons[current_season]['test']] + ['-1']),
            last_run = last_run,
            exclude_next_testruns = ','.join(str(r) for r in exclude_next_testruns + ['-1'])
    )
   
    logger.debug("SQL to get data from live: {0}".format(livesql))

    i3live_query = db_i3live.fetchall(livesql)

    if not len(i3live_query):
        logger.info("no results from i3Live DB for runs >= {first_run}".format(first_run = first_run))
        return counter

    # dict structure of live db data ensures only latest entry for every run is considered
    run_data = {}

    # Need to catch all run id/snapshot id combinations of all runs
    # That means that it needs to be aware of that one run can have several entries/snapshot ids
    run_snapshot_id_mapping = {}

    for row in i3live_query:
        run_data[row['runNumber']] = row

        # Add run id/snapshot id combination
        run_snapshot_id_mapping[row['runNumber']] = row['snapshot_id']

    run_ids = run_data.keys()
    run_ids.sort()

    run_snapshot_id_str = ",".join(["'{run_id}_{snapshot_id}'".format(run_id = run_id, snapshot_id = snapshot_id) for run_id, snapshot_id in run_snapshot_id_mapping.items()])

    # get all previous runs from filter-db and check if entries in live are different
    runs_in_production_db = db_filter.fetchall("SELECT run_id FROM i3filter.runs ORDER BY run_id")
    new_data = list(set(run_ids) - set([row['run_id'] for row in runs_in_production_db]))
    new_data.sort()
   
    old_data_sql = """
        SELECT run_id
        FROM i3filter.runs
        WHERE CONCAT(run_id, "_", snapshot_id) IN ({run_snapshot_id_str})
        ORDER BY run_id""".format(run_snapshot_id_str = run_snapshot_id_str)

    logger.debug("SQL to get old data from production DB: {0}".format(old_data_sql))

    old_data = [row['run_id'] for row in db_filter.fetchall(old_data_sql)]

    changed_data_sql = """
        SELECT run_id, snapshot_id
        FROM i3filter.runs
        WHERE (run_id >= {first_run} OR run_id IN ({test_runs}))
           AND run_id <= {last_run}
           AND run_id NOT IN ({exclude_next_testruns})
        ORDER BY run_id""".format(
            first_run = first_run,
            test_runs = ','.join([str(r) for r in seasons[current_season]['test']] + ['-1']),
            last_run = last_run,
            exclude_next_testruns = ','.join(str(r) for r in exclude_next_testruns)
    )

    logger.debug("SQL to get data from production DB for changed records: {0}".format(changed_data_sql))

    changed_data = db_filter.fetchall(changed_data_sql)

    ignored_run_snapshots = get_ignored_run_snapshots(db_filter, logger)

    # Find out which records have been changed. That means which run has a new snapshot
    # Check which RunId/SnapShotId combinations are already in the DB

    logger.debug("Information from i3live about run/snapshot mapping: {0}".format(run_snapshot_id_mapping))

    new_snapshot_for_run = {}
    for run_id, snapshot_id in run_snapshot_id_mapping.items():
        found = False

        for c in changed_data:
            if run_id == c['run_id'] and snapshot_id == c['snapshot_id']:
                found = True
                break

        for i in ignored_run_snapshots:
            if run_id == i['run_id'] and snapshot_id == i['snapshot_id']:
                found = True
                break

        logger.debug("run_id = {run_id}, snapshot_id = {snapshot_id}, found = {found}".format(run_id = run_id, snapshot_id = snapshot_id, found = found))

        if not found:
            for c in changed_data:
                if run_id == c['run_id']:
                    new_snapshot_for_run[run_id] = snapshot_id
                    break

    if len(new_snapshot_for_run):
        logger.info("The following records have changed and will result in an update to the production_version {0}".format(new_snapshot_for_run))

        if not check:
            if cron:
                logger.warning('Updated runs are included. Manual check is required.')

                message_run_links = ', '.join('<a href="https://live.icecube.wisc.edu/run/{0}/">{0}</a>'.format(r) for r in new_snapshot_for_run)

                message = "The following records have changed and will result in an update to the production_version {0}".format(message_run_links)
                message += '\nYou need to review and approve those updates manually.'

                send_custom_message(os.path.basename(__file__), 'Updated runs in snapshot. Manual check required.', message, logger, dryrun)

                exit(0)
            else:
                actions = updated_runs_manual_check(new_snapshot_for_run, logger)

                logger.debug('new_snapshot_for_run = {}'.format(new_snapshot_for_run))

                for action in actions:
                    if new_snapshot_for_run[action['run_id']] == action['snapshot_id'] and action['action'] == 'I':
                        del new_snapshot_for_run[action['run_id']]

                logger.debug('new_snapshot_for_run = {}'.format(new_snapshot_for_run))

                mark_ignored_run_snapshots(actions, db_filter, logger, dryrun)

    changed_runs = new_snapshot_for_run
    if len(changed_runs):
        current_info['production_version'] += 1

    if not len(new_data) and not len(changed_runs):
        logger.info("No records to be inserted/updated. Exiting.")
        return counter

    if check:
        logger.info("New records available. This was only a check. Do nothing. Exit.")
        send_check_notification(new_data, changed_runs, logger, dryrun)
        return counter

    logger.info('Found: new runs = {new_runs}, updated runs = {updated_runs}'.format(new_runs = len(new_data), updated_runs = len(changed_runs)))

    for r in run_ids:
        current_run_data = run_data[r]

        run = Run(r, logger)
        run.set_data(
            tstart = current_run_data['tStart'],
            tstart_frac = current_run_data['tStart_frac'] or 0,
            good_tstart = current_run_data['good_tstart'] or current_run_data['tStart'],
            good_tstart_frac = current_run_data['good_tstart_frac'] or current_run_data['tStart_frac'] or 0,
            tstop = current_run_data['tStop'],
            tstop_frac = current_run_data['tStop_frac'] or 0,
            good_tstop = current_run_data['good_tstop'] or current_run_data['tStop'],
            good_tstop_frac = current_run_data['good_tstop_frac'] or current_run_data['tStop_frac'] or 0,
            good_i3 = current_run_data['good_i3'],
            good_it = current_run_data['good_it'],
            snapshot_id = current_run_data['snapshot_id'],
            production_version = current_info['production_version'],
            nevents = current_run_data['nEvents'] or 0,
            rate = current_run_data['rateHz'] or 0,
            reason_i3 = current_run_data['reason_i3'] or '',
            reason_it = current_run_data['reason_it'] or ''
        )

        logger.debug('Current run data: {0}'.format(current_run_data))
        logger.debug('Current run._data: {0}'.format(run._data))

        logger.debug('Current good_tstart: {0}'.format(run.get_good_start_time()))

        logger.debug("Is run {run_id} a good run? = {is_good_run}".format(run_id = run.run_id, is_good_run = run.is_good_run()))

        check_files = True

        if r in old_data:
            continue

        counter.count('handled')

        if r in new_data:
            run_info = []

            if run.is_test_run():
                run_info.append("test run")

            if run.is_good_run():
                run_info.append("good run")
            else:
                run_info.append("bad run")

            logger.info("Entering new records for run = {0}, snapshot_id = {1}, production_version = {2}: {3}".format(r, run.get_snapshot_id(), run.get_production_version(), ', '.join(run_info)))

            in_files = None

            if inputfiletype == 'PFFilt':
                in_files = run.get_pffilt_files()
            elif inputfiletype == 'PFDST':
                in_files = run.get_pfdst_files()
            else:
                raise Exception('File type `{0}` cannot be handled'.format(inputfiletype))

            detailed_info = {}
            check_files = validate_file_integrity(run = run, files = in_files, logger = logger, show_mismatches = run.is_good_run() or run.is_test_run(), detailed_info = detailed_info)

            # Print files that are empty or have wrong permissions
            detailed_info = detailed_info[run.run_id]

            if len(detailed_info['empty_files']) > 0 or len(detailed_info['wrong_permission']) > 0:
                logger.warning("Run {run_id} has issues with input files".format(run_id = run.run_id))

                logger.warning('  Empty files:')
                for f in detailed_info['empty_files']:  
                    logger.warning('    ' + f )

                logger.warning('  Files w/o reading permission:')
                for f in detailed_info['wrong_permission']:
                    logger.warning('    ' + f)

            logger.debug("Check files returned {0}".format(check_files))
            logger.debug("detailed_info = {0}".format(detailed_info))

        update_comment = None
        if r in changed_runs.keys():
            logger.info("updating records for run = {0}".format(r))
            update_comment = 'Updated in snapshot {0}'.format(run.get_snapshot_id())
            counter.count('updated')

        # Insert new runs from live in filter-db
        if check_files or skip_file_validation or (not run.is_good_run() and (not run.is_test_run() or run.is_failed_run())):
            if skip_file_validation and (check_files or (not run.is_good_run() and (not run.is_test_run() or run.is_failed_run()))):
                logger.warning('File check was negative but result will be ignored.')

            logger.info('Insert run into database')

            run_insertion_sql = """
                INSERT INTO `i3filter`.`runs` (
                    `run_id`, `snapshot_id`, `production_version`, `good_i3`, `good_it`, `reason_i3`, `reason_it`,
                    `good_tstart`, `good_tstart_frac`, `good_tstop`, `good_tstop_frac`, `tstart`, `tstart_frac`, `tstop`, `tstop_frac`,
                    `nevents`, `rate`
                ) VALUES (
                    %(run_id)s, %(snapshot_id)s, %(production_version)s, %(good_i3)s, %(good_it)s, %(reason_i3)s, %(reason_it)s,
                    %(good_tstart)s, %(good_tstart_frac)s, %(good_tstop)s, %(good_tstop_frac)s, %(tstart)s, %(tstart_frac)s,
                    %(tstop)s, %(tstop_frac)s, %(nevents)s, %(rate)s
                )
            """

            run_insertion_args = {
                    'run_id': run.run_id,
                    'snapshot_id': run.get_snapshot_id(),
                    'production_version': run.get_production_version(),
                    'good_i3': int(run.is_good_in_ice_run()),
                    'good_it': int(run.is_good_ice_top_run()),
                    'reason_i3': current_run_data['reason_i3'],
                    'reason_it': current_run_data['reason_it'],
                    'good_tstart': times.get_db_time(run.get_good_start_time()),
                    'good_tstart_frac': times.get_db_frac(run.get_good_start_time()),
                    'good_tstop': times.get_db_time(run.get_good_stop_time()),
                    'good_tstop_frac': times.get_db_frac(run.get_good_stop_time()),
                    'tstart': current_run_data['tStart'],
                    'tstart_frac': current_run_data['tStart_frac'] or 0,
                    'tstop': current_run_data['tStop'],
                    'tstop_frac': current_run_data['tStop_frac'] or 0,
                    'nevents': run.get_number_of_events(),
                    'rate': run.get_rate()
            }

            if update_comment is not None:
                comment_insertion_sql = """
                    INSERT INTO `i3filter`.`run_comments`
                    (`run_id`,
                    `snapshot_id`,
                    `production_version`,
                    `date`,
                    `comment`)
                    VALUES
                    (%(run_id)s,
                    %(snapshot_id)s,
                    %(production_version)s,
                    NOW(),
                    %(comment)s)
                """

            comment_insertion_args = {
                'run_id': run.run_id,
                'snapshot_id': run.get_snapshot_id(),
                'production_version': run.get_production_version(),
                'comment': update_comment
            }

            logger.debug('Run insertion SQL: {0}'.format(run_insertion_sql))
            if not dryrun:
                db_filter.execute(run_insertion_sql, run_insertion_args)

                if update_comment is not None:
                    logger.info('Insert comment: {0}'.format(update_comment))
                    db_filter.execute(comment_insertion_sql, comment_insertion_args)

            counter.count('imported')
        else:
            counter.count('error')

    logger.info('Run import complete: {0}'.format(counter.get_summary()))
    return counter

if __name__ == "__main__":
    parser = get_defaultparser(__doc__, dryrun = True)
    parser.add_argument('--check', help="Only check for updates. Do nothing else", action = "store_true", default = False)
    parser.add_argument("--cron", action = "store_true", default = False, help = "Use this option if you call this script via a cron")
    parser.add_argument('--skip-file-validation', help="Skip file check. Ignores if input files do not exists or similar.", action = "store_true", default = False)
    parser.add_argument('--inputfiletype', help="What is the input file type? Available options: PFDST, PFFilt. Default is PFFilt", default = 'PFFilt', required = False)
    args = parser.parse_args()

    logfile = os.path.join(get_logdir(sublogpath = 'PreProcessing'), 'GetRunInfo_')

    if args.cron:
        logfile += 'CRON_'

    if args.logfile is not None:
        logfile = args.logfile

    logger = get_logger(args.loglevel, logfile)

    config = get_config(logger)

    if args.inputfiletype not in ['PFDST', 'PFFilt']:
        logger.critical('Input file type must match `PFDST` or `PFFilt`.')
        exit(1)

    # Check if --cron option is enabled. If so, check if cron usage allowed by config
    lock = None
    if args.cron:
        if not config.getboolean('GetRunInfo', 'CronEnabled'):
            logger.critical('It is currently not allowed to execute this script as cron. Check config file.')
            exit(1)

        # Check if cron is already running
        lock = Lock(os.path.basename(__file__), logger)
        lock.lock()

    counter = main(inputfiletype = args.inputfiletype, logger = logger, dryrun = args.dryrun, check = args.check, skip_file_validation = args.skip_file_validation, cron = args.cron)

    if args.cron:
        lock.unlock()
        cron_finished(os.path.basename(__file__), counter, logger, args.dryrun)

    logger.info('Done')
