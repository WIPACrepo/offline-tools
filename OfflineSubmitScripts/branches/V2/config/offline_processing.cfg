[DEFAULT]
; Additional defaults are (defined in libs/config.py by using libs/files.py):
;   tmpdir = temporary directory
;   rootdir = root directory of the offline processing scripts
;   logdir = base directory for log files

; Seasons
; Current season
Season = 2016

; Meta data file
MetaFileTemplateMainProcessing = %(rootdir)s/config/meta_template.xml

; ########################################
; ##### PERSONNEL ########################
; ########################################
[PERSONNEL]
; Personnel information is required for meta data
FirstName = Jan
LastName = Oertlin
eMail = jan.oertlin@icecube.wisc.edu

; ########################################
; ##### GCDGeneration ####################
; ########################################
[GCDGeneration]
; SPE correction not needed if used with gcdserver
SpeCorrectionFile = ${Level2:I3_SRC}/filterscripts/resources/data/final-spe-fits-pole-run2016_MAY.json.bz2

TmpCondorSubmitFile = %(tmpdir)s/submit_GCD.condor
CondorLog = ${Level2:OutputBasePath}/OfflinePreChecks/run_logs/condor_logs/{month:0>2}{day:0>2}/Run{run_id:0>8}_{production_version}_{snapshot_id}.log
CondorErrorLog = ${Level2:OutputBasePath}/OfflinePreChecks/run_logs/condor_err/{month:0>2}{day:0>2}/Run{run_id:0>8}_{production_version}_{snapshot_id}.err
OutLog = ${Level2:OutputBasePath}/OfflinePreChecks/run_logs/logs/{month:0>2}{day:0>2}/Run{run_id:0>8}_{production_version}_{snapshot_id}.out

I3LiveHost = live.icecube.wisc.edu
MongoDBHost = mongodb-live

; Current RC doesn't have the GCDDiff exit code fix
; GCDCompareTool = ${Level2:I3_SRC}/gcdserver/resources/GCDDiff.py

; Temporary solution?!
GCDCompareTool = /home/joertlin/workspace/gcdserver/trunk/resources/GCDDiff.py

; ########################################
; ##### GCD ##############################
; ########################################
[GCD]
GCDDataPath = ${Level2:OutputBasePath}/OfflinePreChecks/DataFiles/{month:0>2}{day:0>2}/Level2_IC86.{season}_data_Run{run_id:0>8}_{production_version}_{snapshot_id}_GCD.i3.gz
AllGCDPath = ${Level2:OutputBasePath}/AllGCD/Level2_IC86.{season}_data_Run{run_id:0>8}_{month:0>2}{day:0>2}_{production_version}_{snapshot_id}_GCD.i3.gz
VerifiedGCDPath = ${Level2:OutputBasePath}/VerifiedGCD/Level2_IC86.{season}_data_Run{run_id:0>8}_{month:0>2}{day:0>2}_{production_version}_{snapshot_id}_GCD.i3.gz

BadDomListName = BadDomsList
BadDomListNameSLC = BadDomsListSLC

; Note that the SPS GCD files do NOT have leading zeros for the run id!
SPSGCDFile = /data/exp/IceCube/{year}/internal-system/sps-gcd/{month:0>2}{day:0>2}/SPS-GCD_Run{run_id}.i3.tar.gz

; ########################################
; ##### GCD Pass2 ########################
; ########################################
[GCDPass2]
GCDDataPath = ${Level2pass2:OutputBasePath}/OfflinePreChecks/DataFiles/{month:0>2}{day:0>2}/Level2_IC86.{season}_data_Run{run_id:0>8}_{production_version}_{snapshot_id}_GCD.i3.gz
AllGCDPath = ${Level2pass2:OutputBasePath}/AllGCD/Level2_IC86.{season}_data_Run{run_id:0>8}_{month:0>2}{day:0>2}_{production_version}_{snapshot_id}_GCD.i3.gz
VerifiedGCDPath = ${Level2pass2:OutputBasePath}/VerifiedGCD/Level2_IC86.{season}_data_Run{run_id:0>8}_{month:0>2}{day:0>2}_{production_version}_{snapshot_id}_GCD.i3.gz

BadDomListName = BadDomsList
BadDomListNameSLC = BadDomsListSLC

; ########################################
; ##### PFDST ############################
; ########################################
[PFDST]

PFDSTFile = /data/exp/IceCube/{year}/unbiased/PFDST/{month:0>2}{day:0>2}/PFDST_PhysicsFiltering_Run{run_id:0>8}_Subrun00000000_{sub_run_id:0>8}.tar.gz

RegExpForSubRunId = ^/.*Subrun[0]{8}_+([0-9]{8}).*$

; ########################################
; ##### PFFilt ###########################
; ########################################
[PFFilt]

PFFiltFile = /data/exp/IceCube/{year}/filtered/PFFilt/{month:0>2}{day:0>2}/PFFilt_PhysicsFiltering_Run{run_id:0>8}_Subrun00000000_{sub_run_id:0>8}.tar.bz2

RegExpForSubRunId = ^/.*Subrun[0]{8}_+([0-9]{8}).*$

; ########################################
; ##### L2 ###############################
; ########################################
[Level2]
; The src and build directory that should be used
I3_BUILD = /data/user/i3filter/IC86_OfflineProcessing/icerec/RHEL_6.4_V05-01-00-RC9
I3_SRC = /data/user/i3filter/IC86_OfflineProcessing/icerec/V05-01-00-RC9

; Paths
; You can use {year}, {season}, {day}, {month}, {production_version}, {run_id}, {snapshot_id}, {now} (datetime), {sub_run_id}
; if available for those paths.
; OutputBasePath = /data/exp/IceCube/{year}/filtered/level2
OutputBasePath = /data/user/joertlin/V2Test/{year}/filtered/level2

; The path where all the level2 files should be stored
RunFolder = ${Level2:OutputBasePath}/{month:0>2}{day:0>2}/Run{run_id:0>8}_{production_version}

; Name of the GCD file in the run folder. MUST be a absolute path
RunFolderGCD = ${Level2:RunFolder}/Level2_IC86.{season}_data_Run{run_id:0>8}_{month:0>2}{day:0>2}_{production_version}_{snapshot_id}_GCD.i3.gz

; After the run has been validated, a sym link to the folder will be created that has no prodiction version information.
; For instance, it could point to `Run00123456 -> Run00123456_99`.
RunLinkName = ${Level2:OutputBasePath}/{month:0>2}{day:0>2}/Run{run_id:0>8}

; If a sub run is entirely or partly not within the good start/stop time range, the file will be moved to a (sub)folder to
; make sure that those files are not accidently used. This option specifies the folder for those subr runs
BadSubRunFolder = ${Level2:RunFolder}/Bad_NotWithinGoodRunRange

; Good run list (GRL) options. After each post processing, a new GRL will be created and if new entries were added, the file will be kept.
; Any version of the GRL will be kept in the `GRLFolder`. The file name is `GRLFileName`. Since there is always a 'GRL' and a 'Versioned GRL'
; ('Versioned GRL' means, that the `RunFolder` path is used instead of `RunLinkName`) you need to specify both file names.
GRLFolder = ${Level2:OutputBasePath}/RunInfo
GRLFileName = ${Level2:GRLFolder}/IC86_{season}_GoodRunInfo_{production_version}_{now:%%Y_%%m_%%d-%%H_%%M_%%S}.txt
GRLFileVersionedName = ${Level2:GRLFolder}/IC86_{season}_GoodRunInfo_{production_version}_Versioned_{now:%%Y_%%m_%%d-%%H_%%M_%%S}.txt

; The latest GRL has a sym link in the level2 base folder. Those options specify the link names
GRLLinkName = ${Level2:OutputBasePath}/IC86_{season}_GoodRunInfo.txt
GRLLinkVersionedName = ${Level2:OutputBasePath}/IC86_{season}_GoodRunInfo_Versioned.txt

; The actual file names. Note that this MUST always be absolute paths!
; Also note, that those filenames must match the config in iceprod!
Level2File = ${Level2:RunFolder}/Level2_IC86.{season}_data_Run{run_id:0>8}_Subrun{sub_run_id:0>8}.i3.bz2
GapsFile = ${Level2:RunFolder}/Level2_IC86.{season}_data_Run{run_id:0>8}_Subrun{sub_run_id:0>8}_gaps.txt

; Regular expression  to find the sub run id in the path.
RegExpForSubRunId = ^/.*Subrun0+([0-9]+).*$

; All gaps files will be tar-ed and then removed. Only the tar-ed version will be kept. This option specifies
; the name of the tar-ed version
GapsTarFile = ${Level2:RunFolder}/Run{run_id:0>8}_GapsTxt.tar

; A couple of log files are written to the datawarehouse. They will also be tar-ed and removed. Only the tar-ed
; version will be kept. This option specifies the tar file name.
TarLogFileName = ${Level2:RunFolder}/logfiles.tar.bz2

; Here you can specify as many glob strings as you want to find all log files. Note that you
; also can still use {year}, {run_id} etc. but NOT {sub_run_id}
; Be careful not to make a glob that includes data files!
; Note that the variable name MUST start with `LogFileGlob` followed by a number!
LogFileGlob1 = ${Level2:RunFolder}/*.logerr
LogFileGlob2 = ${Level2:RunFolder}/*.logicetray
LogFileGlob3 = ${Level2:RunFolder}/*.logout

; Meta data file
; NOTE: This is the only "path" that is NOT!!!! NOT an absolute path. It is just the file name.
MetaFileName = level2_meta.xml

; Allow L2 post processing with crons
CronPostProcessing = On

; ########################################
; ##### L2 Pass2 #########################
; ########################################
[Level2pass2]

; Paths
OutputBasePath = /data/exp/IceCube/{year}/filtered/Level2pass2

RunFolder = ${Level2pass2:OutputBasePath}/{month:0>2}{day:0>2}/Run{run_id:0>8}_{production_version}
RunFolderGCD = ${Level2pass2:RunFolder}/Level2_IC86.{season}_data_Run{run_id:0>8}_{month:0>2}{day:0>2}_{production_version}_{snapshot_id}_GCD.i3.gz
RunLinkName = ${Level2pass2:OutputBasePath}/{month:0>2}{day:0>2}/Run{run_id:0>8}

GRLFolder = ${Level2pass2:OutputBasePath}/RunInfo
GRLFileName = ${Level2pass2:GRLFolder}/IC86_{season}_GoodRunInfo_{production_version}_{now:%%Y_%%m_%%d-%%H_%%M_%%S}.txt
GRLFileVersionedName = ${Level2pass2:GRLFolder}/IC86_{season}_GoodRunInfo_{production_version}_Versioned_{now:%%Y_%%m_%%d-%%H_%%M_%%S}.txt
GRLLinkName = ${Level2pass2:OutputBasePath}/IC86_{season}_GoodRunInfo.txt
GRLLinkVersionedName = ${Level2pass2:OutputBasePath}/IC86_{season}_GoodRunInfo_Versioned.txt

Level2pass2File = ${Level2pass2:RunLinkName}/Level2_IC86.{season}_data_Run{run_id:0>8}_Subrun{sub_run_id:0>8}.i3.bz2
GapsFiles = ${Level2pass2:RunLinkName}/Level2_IC86.{season}_data_Run{run_id:0>8}_Subrun{sub_run_id:0>8}_gaps.txt

RegExpForSubRunId = ^/.*Subrun0+([0-9]+).*$

; ########################################
; ##### L3 ###############################
; ########################################
[Level3]
; Working Group Names
WorkingGroup1 = Muon
WorkingGroup2 = Low Energy
WorkingGroup3 = Cascade
WorkingGroup4 = CosmicRay

; Mapping of the dataset and output folder:
; The key must start with 'DatasetOutputDirMapping' followed by the dataset number
DatasetOutputDirMapping1885 = /data/ana/Muon/level3/exp/
DatasetOutputDirMapping1889 = /data/ana/Muon/level3/exp/
DatasetOutputDirMapping1890 = /data/ana/LE/level3/exp/
DatasetOutputDirMapping1891 = /data/ana/Cscd/IC86-5/level3/exp/
DatasetOutputDirMapping1892 = /data/ana/Cscd/IC86-6/level3/exp/
DatasetOutputDirMapping1893 = /data/ana/LE/level3/exp/
DatasetOutputDirMapping1894 = /data/ana/LE/level3/exp/
DatasetOutputDirMapping1895 = /data/ana/LE/level3/exp/
DatasetOutputDirMapping1896 = /data/ana/LE/level3/exp/
DatasetOutputDirMapping1898 = /data/ana/Muon/level3/exp/
DatasetOutputDirMapping1901 = /data/ana/CosmicRay/IceTop_level3/exp/test_data/IC86.2011/
DatasetOutputDirMapping1902 = /data/ana/CosmicRay/IceTop_level3/exp/test_data/IC86.2013/
DatasetOutputDirMapping1905 = /data/ana/CosmicRay/IceTop_level3/exp/test_data/IC86.2012/
DatasetOutputDirMapping1906 = /data/ana/CosmicRay/IceTop_level3/exp/test_data/IC86.2014/
DatasetOutputDirMapping1908 = /data/ana/CosmicRay/IceTop_level3/exp/test_data/IC86.2015/

; Mapping of the working groups
WG1885 = %(WorkingGroup1)s
WG1889 = %(WorkingGroup1)s
WG1890 = %(WorkingGroup2)s
WG1891 = %(WorkingGroup3)s
WG1892 = %(WorkingGroup3)s
WG1893 = %(WorkingGroup2)s
WG1894 = %(WorkingGroup2)s
WG1895 = %(WorkingGroup2)s
WG1896 = %(WorkingGroup2)s
WG1898 = %(WorkingGroup1)s
WG1901 = %(WorkingGroup4)s
WG1902 = %(WorkingGroup4)s
WG1905 = %(WorkingGroup4)s
WG1906 = %(WorkingGroup4)s
WG1908 = %(WorkingGroup4)s

; The src and build directory that should be used for each dataset
; Note that the keys MUST follow the pattern 'I3_SRC_YYYY' and "I3_BUILD_YYYY' whereby YYYY the dataset id is
I3_SRC_1885 = /data/user/i3filter/IC86_OfflineProcessing/icerec/IC2015-L3_Muon_V5
I3_BUILD_1885 = /data/user/i3filter/IC86_OfflineProcessing/icerec/RHEL_6.4_IC2015-L3_Muon_V5

I3_SRC_1889 = /data/user/i3filter/IC86_OfflineProcessing/icerec/IC2015-L3_Muon_V5
I3_BUILD_1889 = /data/user/i3filter/IC86_OfflineProcessing/icerec/RHEL_6.4_IC2015-L3_Muon_V5

I3_SRC_1890 = /data/user/i3filter/IC86_OfflineProcessing/icerec/V05-00-01
I3_BUILD_1890 = /data/user/i3filter/IC86_OfflineProcessing/icerec/RHEL_6.4_V05-00-01

I3_SRC_1891 = /data/user/i3filter/IC86_OfflineProcessing/icerec/V05-00-01
I3_BUILD_1891 = /data/user/i3filter/IC86_OfflineProcessing/icerec/RHEL_6.4_V05-00-01

I3_SRC_1892 = /data/user/i3filter/IC86_OfflineProcessing/icerec/V05-00-01
I3_BUILD_1892 = /data/user/i3filter/IC86_OfflineProcessing/icerec/RHEL_6.4_V05-00-01

I3_SRC_1893 = /data/user/i3filter/IC86_OfflineProcessing/icerec/V05-00-04
I3_BUILD_1893 = /data/user/i3filter/IC86_OfflineProcessing/icerec/RHEL_6.4_V05-00-04

I3_SRC_1894 = /data/user/i3filter/IC86_OfflineProcessing/icerec/V05-00-02
I3_BUILD_1894 = /data/user/i3filter/IC86_OfflineProcessing/icerec/RHEL_6.4_V05-00-02

I3_SRC_1895 = /data/user/i3filter/IC86_OfflineProcessing/icerec/V05-00-02
I3_BUILD_1895 = /data/user/i3filter/IC86_OfflineProcessing/icerec/RHEL_6.4_V05-00-02

I3_SRC_1896 = /data/user/i3filter/IC86_OfflineProcessing/icerec/V05-00-02
I3_BUILD_1896 = /data/user/i3filter/IC86_OfflineProcessing/icerec/RHEL_6.4_V05-00-02

I3_SRC_1898 = /data/user/i3filter/IC86_OfflineProcessing/icerec/IC2015-L3_Muon_V5
I3_BUILD_1898 = /data/user/i3filter/IC86_OfflineProcessing/icerec/RHEL_6.4_IC2015-L3_Muon_V5

I3_SRC_1901 = /data/user/i3filter/IC86_OfflineProcessing/icerec/V05-01-00-RC5_CR_Test
I3_BUILD_1901 = /data/user/i3filter/IC86_OfflineProcessing/icerec/RHEL_6.4_V05-01-00-RC5_CR_Test

I3_SRC_1902 = /data/user/i3filter/IC86_OfflineProcessing/icerec/V05-01-00-RC5_CR_Test
I3_BUILD_1902 = /data/user/i3filter/IC86_OfflineProcessing/icerec/RHEL_6.4_V05-01-00-RC5_CR_Test

I3_SRC_1905 = /data/user/i3filter/IC86_OfflineProcessing/icerec/V05-01-00-RC5_CR_Test
I3_BUILD_1905 = /data/user/i3filter/IC86_OfflineProcessing/icerec/RHEL_6.4_V05-01-00-RC5_CR_Test

I3_SRC_1906 = /data/user/i3filter/IC86_OfflineProcessing/icerec/V05-01-00-RC5_CR_Test
I3_BUILD_1906 = /data/user/i3filter/IC86_OfflineProcessing/icerec/RHEL_6.4_V05-01-00-RC5_CR_Test

I3_SRC_1908 = /data/user/i3filter/IC86_OfflineProcessing/icerec/V05-01-00-RC5_CR_Test
I3_BUILD_1908 = /data/user/i3filter/IC86_OfflineProcessing/icerec/RHEL_6.4_V05-01-00-RC5_CR_Test

; Meta data file
MetaFileName = level3_meta.xml

; Managing crons
CronMainSubmission = On
CronPostProcessing = On

; Only runs between CronRunStart and CronRunEnd are handled by the cron
CronRunStart = 127950
CronRunEnd = 999999

; Installing crons
; ---------------
; Main processing starts with 'CronJobMainProcessing' followed by the L3 dataset id. The value
; of this variable must be the source dataset (usually an L2 dataset)
#CronJobMainProcessing1892 = 1888
CronJobMainProcessing1893 = 1888
CronJobMainProcessing1889 = 1888

; Post processing starts with 'CronJobPostProcessing' followed by the L3 dataset id. The value
; of this variable must be the source dataset (usually an L2 dataset)
#CronJobPostProcessing1892 = 1888
CronJobPostProcessing1893 = 1888
CronJobPostProcessing1889 = 1888

; ########################################
; ##### PoleGCDChecks ####################
; ########################################
[PoleGCDChecks]
; Log file for a specific run
RunLogFile = %(logdir)s/PoleGCDChecks/Run{run_id:0>8}.log

; Receivers for notifications: The key must start with 'NotificationReceiver' followed by an unique number
NotificationReceiver1 = drwilliams3@ua.edu
NotificationReceiver2 = john.kelley@icecube.wisc.edu
NotificationReceiver3 = matt.kauer@icecube.wisc.edu
NotificationReceiver4 = tomas.j.palczewski@ua.edu
NotificationReceiver6 = jan.oertlin@icecube.wisc.edu

; ########################################
; ##### TemplateGCDChecks ################
; ########################################
[TemplateGCDChecks]
; The default start run to compare the GCD files. Usually the first run of the season
DefaultStartRun = 127950

; Receivers for notifications: The key must start with 'NotificationReceiver' followed by an unique number
NotificationReceiver1 = drwilliams3@ua.edu
NotificationReceiver2 = john.kelley@icecube.wisc.edu
NotificationReceiver3 = matt.kauer@icecube.wisc.edu
NotificationReceiver4 = tomas.j.palczewski@ua.edu
NotificationReceiver5 = david.delventhal@icecube.wisc.edu
NotificationReceiver7 = jan.oertlin@icecube.wisc.edu

; ########################################
; ##### CacheCheckSums ###################
; ########################################
[CacheCheckSums]
; The absolute path of the cache file
CacheFile = %(tmpdir)s/checksum_cache.json

; How many *days* should the script look back?
LookBack = 14

; After how many calculated MD5 sums should those be written to the cache file?
DumpInterval = 40

; How old must be the file before it will be indexed?
; This should be at least a few minutes to avoid MD5 check sums of an incompleted file
; Unit is seconds
HoldOffInterval = 300

; Paths that should be checked: You can use {year}, {month}, {day} but {run_id}, {sub_run_id}, {production_version}, and {snapshot_id} will be replaced by *
; Note: You can add several paths but the variable needs to start with `Path` followed by a number
Path1 = ${PFFilt:PFFiltFile}
; Path2 = ${PFDST:PFDSTFile}

; ########################################
; ##### GetRunInfo #######################
; ########################################
[GetRunInfo]
; There is a cron that checks once a day if a new snapshot is available.
; If a new snapshot is available, the following receivers will get a email notification
; The key must start with 'NotificationReceiver' followed by an unique number
NotificationReceiver1 = jan.oertlin@icecube.wisc.edu

; ########################################
; ##### Notifications ####################
; ########################################
[Notifications]
eMailSender = jan.oertlin
eMailDomain = @icecube.wisc.edu
eMailMimeVersion = 1.0
eMailContentType = text/html

; ########################################
; ##### Logger ###########################
; ########################################
[Logger]
; Using python logger
;Format = [%%(asctime)s] %%(levelname)s: %%(module)s(%%(lineno)d):   %%(message)s


